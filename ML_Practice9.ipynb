{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f8f677-fc2f-481c-afec-5f627f8c866a",
   "metadata": {},
   "source": [
    "# What is cost Function:\n",
    "- A cost function is an important parameter that determines how well a machine learning model performs for a given dataset.\n",
    "- Cost function is a measure of how wrong the model is in estimating the relationship between X(input) and Y(output) parameter.\n",
    "- Note: In regression we will get best fit line but if we talk about classification than it can be anything like plan, line etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a26847-931c-419d-ae94-128ad8fecb91",
   "metadata": {},
   "source": [
    "# Type of COST function:\n",
    "1. Regression Cost Function\n",
    "2. Classification cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f12af0-c2f4-402d-af72-e7262152b90b",
   "metadata": {},
   "source": [
    "# Regression Cost Function:\n",
    "- Regression models are used to make a prediction for the continuous variables.\n",
    "   - MSE (Mean Square Error)\n",
    "   - RMSE (Root Mean Square Error)\n",
    "   - MAE (Mean Absolute Error)\n",
    "   - R^2 Accuracy\n",
    "\n",
    "# Classification Cost Function:\n",
    "1. Binary Classification Cost Function:\n",
    "   - Classification models are used to make predictions of categorical variables, such as predictions for 0 or 1, cat or dog, True or False, etc.\n",
    "  \n",
    "     \n",
    "2. Multi-class Classification Cost Function:\n",
    "   - A multi-class classification cost function is used in the classification problems for which instances are allocated to one of more than two class.\n",
    "   - Ex: (Cat, Dog, Elephant)\n",
    "   - Ex: (0,1,2,3)\n",
    "   - Ex: (10,20,30)\n",
    "   - Binary cross Entropy cost function or log loss function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d39ba2-2cba-44c9-af12-cfb72b2158f2",
   "metadata": {},
   "source": [
    "# Regression Cost Function:\n",
    "1. Mean Squared Error:\n",
    "   - Note: We can't use this error when data contains outliers. Also MSE is a differenciable equation.That's why we easily predict actual output.\n",
    "   - Mean Squared Error(MSE) is the mean squared difference between the actual and predicted values. MSE penalizes high errors caused by outliers by squaring the errors.\n",
    "   - Mean square error is also known as L2 loss.\n",
    "   - MSE = (1/n) * Σ(Yi - Ŷi)²\n",
    "\n",
    "2. Mean Absolute Error:\n",
    "   - Note: When data contains outliers at that time use MAR. Also MAE is not a differenciable equation. That's why we can't predict actual output\n",
    "   - Mean Absolute Error(MAE) is the mean absolute difference between the actual values and the predicted values.\n",
    "   - MAE is more robust to outliers. The insensitivityto outliers is because it does not penalize high errors caused by outliers.\n",
    "   - MAE = (1/n) * Σ |yᵢ - ŷᵢ|\n",
    "\n",
    "3. Root Mean Squared Error:\n",
    "   - Note: When data contains outliers at that time we also use RMSE. Also RMSE is a differenciable equation.\n",
    "   - Root Mean Squared Error (RMSE) is the root squared mean of the difference between actual and predicted values.\n",
    "   - RMSE can be used in situations where we want to penalize high errors but not as much as MSE does.\n",
    "   - RMSE = √[(Σ(yᵢ – ŷᵢ)² ) / n]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c449b7c1-d01e-49e8-bebf-2df669635177",
   "metadata": {},
   "outputs": [],
   "source": [
    " s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
